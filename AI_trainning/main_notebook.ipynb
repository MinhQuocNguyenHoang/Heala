{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b96a051",
   "metadata": {},
   "source": [
    "# ECG PPG Detection Pipeline\n",
    "\n",
    "This notebook provides a step-by-step implementation of the main logic from `main.py` for PPG peaks detection using convolutional neural networks. It covers data preparation, model definition, training, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f720c",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries and Modules\n",
    "\n",
    "Import all necessary libraries and set up the environment for TensorFlow and multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4809587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_5404\\2428965925.py:8: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import csv\n",
    "from make_data import *\n",
    "from util import *\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from multiprocessing import Pool\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d80eb2",
   "metadata": {},
   "source": [
    "## 2. Define PPG peak Detection Model\n",
    "\n",
    "Define the convolutional neural network (CNN) model for QRS detection using TensorFlow Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b93ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppg_model(input_shape=NEIGHBOUR_POINT, learning_rate=0.02, momentum=0.9):\n",
    "    cnn_model = tf.keras.models.Sequential()\n",
    "    cnn_model.add(tf.keras.layers.Conv1D(filters=8, kernel_size=5, padding='same', activation='relu',\n",
    "                                         input_shape=(input_shape, 1), data_format=\"channels_last\", ))\n",
    "    cnn_model.add(tf.keras.layers.MaxPool1D(pool_size=2, strides=2, padding='same'))\n",
    "    cnn_model.add(tf.keras.layers.Conv1D(filters=16, kernel_size=5, padding='same', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.Flatten())\n",
    "    cnn_model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "    cnn_model.summary()\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,momentum=momentum)\n",
    "    loss = tf.keras.losses.binary_crossentropy\n",
    "    cnn_model.compile(optimizer, loss=loss, metrics=['accuracy'])\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907fb7d",
   "metadata": {},
   "source": [
    "## 3. Train the Model\n",
    "\n",
    "Train the QRS detection model using the preprocessed data, TensorBoard, and model checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e19c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, batch_size=128, epoch=1):\n",
    "    if os.path.exists(SAVE_MODEL_DIR + TEST_TIME):\n",
    "        print(f\"Model {TEST_TIME} was trained and is ready\")\n",
    "        return\n",
    "\n",
    "    shuffle_buffer = batch_size * 100\n",
    "    prefetch_buffer = batch_size * 100\n",
    "    train_set = get_record_preprocessed('train')\n",
    "    sample = 0\n",
    "    for file in train_set:\n",
    "        if file.split('.')[1] == '2':\n",
    "            continue\n",
    "        header = wfdb.rdheader(os.path.join(MITDB_DIR, file.split('.')[0]))\n",
    "        sample += header.sig_len - (NEIGHBOUR_POINT - 1) * 2\n",
    "\n",
    "    train_data = get_tf_records(get_record_preprocessed('train'), batch_size, shuffle_buffer, prefetch_buffer)\n",
    "    valid_data = get_tf_records(get_record_preprocessed('eval'), batch_size, shuffle_buffer, prefetch_buffer, mode='eval')\n",
    "\n",
    "    log_dir = TENSOR_BOARD_DIR + TEST_TIME\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "    check_point_dir = CHECK_POINT_DIR + TEST_TIME + '/'\n",
    "    if not os.path.exists(check_point_dir):\n",
    "        os.makedirs(check_point_dir)\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=check_point_dir + \"{epoch:02d}.weights.h5\",\n",
    "                                                    save_weights_only=True, verbose=0, save_freq='epoch')\n",
    "    callback = [tensorboard, checkpoint]\n",
    "    with tf.device(\"/GPU:0\"):\n",
    "        model.fit(train_data,\n",
    "                  steps_per_epoch=int(sample/batch_size),\n",
    "                  epochs=epoch,\n",
    "                  verbose=1,\n",
    "                  validation_data=valid_data,\n",
    "                  callbacks=callback)\n",
    "        model.save(SAVE_MODEL_DIR + TEST_TIME + \"/last_ckt.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe6557",
   "metadata": {},
   "source": [
    "## 4. Evaluate Model on Test Data\n",
    "\n",
    "Evaluate the trained QRS detection model on the test/evaluation data and write results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0908205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_result(result_file_name, checkpoint=True, checkpoint_epoch=0, saved_model_name=None, batch_size=128):\n",
    "#     if not os.path.exists(RESULT_DIR):\n",
    "#         os.makedirs(RESULT_DIR)\n",
    "\n",
    "#     with open(RESULT_DIR + result_file_name + '.csv', 'w', newline='') as result_file:\n",
    "#         writer = csv.writer(result_file)\n",
    "#         writer.writerow([\"Recording\", \"TP\", \"FN\", 'FP', 'Se', 'P+'])\n",
    "\n",
    "#         # Tổng cộng dồn TP, FN, FP\n",
    "#         TP_total = 0\n",
    "#         FN_total = 0\n",
    "#         FP_total = 0\n",
    "\n",
    "#         shuffle_buffer = batch_size * 100\n",
    "#         prefetch_buffer = batch_size * 100\n",
    "\n",
    "#         # Load model\n",
    "#         if checkpoint:\n",
    "#             model = get_qrs_model()\n",
    "#             model.load_weights(CHECK_POINT_DIR + TEST_TIME + \"/0{}.weights.h5\".format(checkpoint_epoch))\n",
    "#             print('Load model checkpoint')\n",
    "#         else:\n",
    "#             model = tf.keras.models.load_model(SAVE_MODEL_DIR + saved_model_name)\n",
    "\n",
    "#         # Lấy danh sách file\n",
    "#         files = get_record_preprocessed('eval')\n",
    "#         for file in files:\n",
    "#             if file.split('.')[0] in ['104', '102', '107', '217']:\n",
    "#                 continue\n",
    "\n",
    "#             test_data = get_tf_records(file, batch_size, shuffle_buffer, prefetch_buffer, mode='eval')\n",
    "#             with tf.device(\"/GPU:0\"):\n",
    "#                 prediction = model.predict(test_data, verbose=0)\n",
    "#             prediction = np.rint(prediction)\n",
    "\n",
    "#             # result = [TP, FN, FP, Se, P+]\n",
    "#             result = evaluate(file.split('.')[0], prediction, MITDB_DIR)\n",
    "#             print(file, result)\n",
    "\n",
    "#             # Cộng dồn TP, FN, FP\n",
    "#             TP_total += result[0]\n",
    "#             FN_total += result[1]\n",
    "#             FP_total += result[2]\n",
    "\n",
    "#             writer.writerow([file, result[0], result[1], result[2], result[3], result[4]])\n",
    "\n",
    "#         # Tính Se và P+ tổng\n",
    "#         Se_total = TP_total / (TP_total + FN_total) if (TP_total + FN_total) > 0 else 0\n",
    "#         Pp_total = TP_total / (TP_total + FP_total) if (TP_total + FP_total) > 0 else 0\n",
    "\n",
    "#         print(['total', TP_total, FN_total, FP_total, Se_total, Pp_total])\n",
    "#         writer.writerow(['total', TP_total, FN_total, FP_total, Se_total, Pp_total])\n",
    "\n",
    "def get_result(result_file_name, checkpoint=True, checkpoint_epoch=0, saved_model_name=None, batch_size=128):\n",
    "    if not os.path.exists(RESULT_DIR):\n",
    "        os.makedirs(RESULT_DIR)\n",
    "\n",
    "    with open(RESULT_DIR + result_file_name + '.csv', 'w', newline='',encoding='utf-8') as result_file:\n",
    "        writer = csv.writer(result_file)\n",
    "        # Sửa Header\n",
    "        writer.writerow(['Recording', 'BPM_Thật (từ .atr)', 'BPM_Dự_đoán (từ Model)', 'Sai_số_BPM (MAE)'])\n",
    "\n",
    "        # Biến đếm tổng sai số\n",
    "        total_bpm_error = 0.0\n",
    "        file_count = 0\n",
    "\n",
    "        shuffle_buffer = batch_size * 100\n",
    "        prefetch_buffer = batch_size * 100\n",
    "\n",
    "        # Load model\n",
    "        if checkpoint:\n",
    "            model = get_ppg_model() # (Đảm bảo đây là model 'tiny')\n",
    "            \n",
    "            # Sửa lỗi load checkpoint:\n",
    "            # Dùng :02d để format số (ví dụ: 03, 10, 20)\n",
    "            checkpoint_path = os.path.join(CHECK_POINT_DIR, TEST_TIME, \"{:02d}.weights.h5\".format(checkpoint_epoch))\n",
    "            model.load_weights(checkpoint_path)\n",
    "            print(f'Load model checkpoint từ: {checkpoint_path}')\n",
    "        else:\n",
    "            model = tf.keras.models.load_model(os.path.join(SAVE_MODEL_DIR, saved_model_name))\n",
    "\n",
    "        # Lấy danh sách file 'eval'\n",
    "        files = get_record_preprocessed('eval')\n",
    "        for file in files:\n",
    "            # Bỏ qua các file không liên quan (nếu có)\n",
    "            if file.split('.')[0] in ['104', '102', '107', '217']:\n",
    "                continue\n",
    "\n",
    "            test_data = get_tf_records(file, batch_size, shuffle_buffer, prefetch_buffer, mode='eval')\n",
    "            with tf.device(\"/GPU:0\"):\n",
    "                prediction = model.predict(test_data, verbose=0)\n",
    "            \n",
    "            # Làm tròn output của model (ví dụ [0.1, 0.9] -> [0., 1.])\n",
    "            prediction = np.rint(prediction)\n",
    "\n",
    "            # --- LOGIC MỚI ---\n",
    "            # Gọi hàm evaluate (đã sửa)\n",
    "            # (Giả định MITDB_DIR là đường dẫn đến file .hea/.atr gốc)\n",
    "            bpm_true, bpm_pred = evaluate(file.split('.')[0], prediction, MITDB_DIR)\n",
    "            \n",
    "            # Tính sai số\n",
    "            bpm_error = 0.0\n",
    "            if bpm_true > 0 and bpm_pred > 0: # Chỉ tính sai số nếu cả 2 đều hợp lệ\n",
    "                bpm_error = np.abs(bpm_true - bpm_pred)\n",
    "                total_bpm_error += bpm_error\n",
    "                file_count += 1\n",
    "\n",
    "            # In kết quả\n",
    "            print(f\"File: {file}, BPM Thật: {bpm_true:.2f}, BPM Dự đoán: {bpm_pred:.2f}, Sai số: {bpm_error:.2f}\")\n",
    "\n",
    "            # Ghi ra CSV\n",
    "            writer.writerow([file, f\"{bpm_true:.2f}\", f\"{bpm_pred:.2f}\", f\"{bpm_error:.2f}\"])\n",
    "\n",
    "        # Tính sai số BPM trung bình toàn bộ\n",
    "        mean_avg_error = total_bpm_error / file_count if file_count > 0 else 0\n",
    "        \n",
    "        print(\"\\n-------------------------------------------------\")\n",
    "        print(f\"SAI SỐ BPM TRUNG BÌNH (MAE): {mean_avg_error:.2f} BPM\")\n",
    "        print(\"-------------------------------------------------\")\n",
    "        \n",
    "        writer.writerow([]) # Dòng trống\n",
    "        writer.writerow(['Total_Mean_Average_Error (BPM)', f\"{mean_avg_error:.2f}\", '', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf92956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │            \u001b[38;5;34m48\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)         │           \u001b[38;5;34m656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,602</span> (53.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,602\u001b[0m (53.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,602</span> (53.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,602\u001b[0m (53.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'SGD', because it has 2 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model checkpoint từ: ./qrs_detection_dataset/checkpoint/mitdb/run-0\\09.weights.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s10_sit.tfrecord, BPM Thật: 75.07, BPM Dự đoán: 74.99, Sai số: 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s11_sit.tfrecord, BPM Thật: 73.06, BPM Dự đoán: 73.33, Sai số: 0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s12_sit.tfrecord, BPM Thật: 72.97, BPM Dự đoán: 72.97, Sai số: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s13_sit.tfrecord, BPM Thật: 74.71, BPM Dự đoán: 74.62, Sai số: 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s14_sit.tfrecord, BPM Thật: 53.97, BPM Dự đoán: 53.75, Sai số: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s15_sit.tfrecord, BPM Thật: 86.07, BPM Dự đoán: 82.96, Sai số: 3.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s16_sit.tfrecord, BPM Thật: 64.60, BPM Dự đoán: 64.63, Sai số: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s17_sit.tfrecord, BPM Thật: 77.23, BPM Dự đoán: 78.93, Sai số: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s18_sit.tfrecord, BPM Thật: 76.59, BPM Dự đoán: 76.62, Sai số: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s19_sit.tfrecord, BPM Thật: 82.40, BPM Dự đoán: 81.75, Sai số: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s1_sit.tfrecord, BPM Thật: 72.66, BPM Dự đoán: 72.68, Sai số: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s20_sit.tfrecord, BPM Thật: 78.95, BPM Dự đoán: 78.91, Sai số: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s21_sit.tfrecord, BPM Thật: 77.81, BPM Dự đoán: 77.84, Sai số: 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s22_sit.tfrecord, BPM Thật: 81.98, BPM Dự đoán: 82.03, Sai số: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s2_sit.tfrecord, BPM Thật: 120.93, BPM Dự đoán: 120.95, Sai số: 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s3_sit.tfrecord, BPM Thật: 73.97, BPM Dự đoán: 74.02, Sai số: 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s4_sit.tfrecord, BPM Thật: 83.19, BPM Dự đoán: 81.79, Sai số: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s5_sit.tfrecord, BPM Thật: 77.77, BPM Dự đoán: 77.78, Sai số: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s6_sit.tfrecord, BPM Thật: 77.72, BPM Dự đoán: 77.78, Sai số: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s7_sit.tfrecord, BPM Thật: 64.73, BPM Dự đoán: 64.73, Sai số: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: s8_sit.tfrecord, BPM Thật: 86.09, BPM Dự đoán: 80.45, Sai số: 5.64\n",
      "File: s9_sit.tfrecord, BPM Thật: 69.95, BPM Dự đoán: 72.03, Sai số: 2.08\n",
      "\n",
      "-------------------------------------------------\n",
      "SAI SỐ BPM TRUNG BÌNH (MAE): 0.71 BPM\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    }
   ],
   "source": [
    "MITDB_DIR = r\"D:\\altium and source projects\\Health monitoring\\physionet.org\\files\\pulse-transit-time-ppg\\1.1.0\"\n",
    "# files = get_record_raw(MITDB_DIR)\n",
    "# print(\"Số file .hea tìm thấy:\", len(files))\n",
    "# print(\"Ví dụ vài file:\", files[:len(files)])\n",
    "# file_test = files[0]\n",
    "# data, label = preprocess_data(file_test, separate=None)\n",
    "# print(\"Shape data:\", data.shape if data is not None else None)\n",
    "# print(\"Shape label:\", label.shape if label is not None else None)\n",
    "# save_tf_record(files[0])\n",
    "# print(\"Danh sách TFRecord:\", [f for f in os.listdir(PREPROCESSED_DATA_DIR) if f.endswith(\".tfrecord\")])\n",
    "# generate_data(get_record_raw(MITDB_DIR), None)\n",
    "# print(\"\\n=== Danh sách TFRecord sinh ra ===\")\n",
    "# print([f for f in os.listdir(PREPROCESSED_DATA_DIR) if f.endswith(\".tfrecord\")])\n",
    "# train_files = get_record_preprocessed(\"train\")\n",
    "# eval_files = get_record_preprocessed(\"eval\")\n",
    "# print(\"Train:\", len(train_files))\n",
    "# print(\"Eval:\", len(eval_files))\n",
    "# train_model(get_ppg_model(), epoch=10)\n",
    "get_result(TEST_TIME, checkpoint=True, checkpoint_epoch=9, saved_model_name='run-0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
