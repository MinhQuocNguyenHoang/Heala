{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "386bfc6a",
   "metadata": {},
   "source": [
    "Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01023fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from define import *\n",
    "import wfdb\n",
    "import numpy as np\n",
    "from scipy.signal import resample\n",
    "from preprocessing import *\n",
    "from util import *\n",
    "from make_data import *\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "004a2b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ppg_model(input_shape=NEIGHBOUR_POINT, learning_rate=0.02, momentum=0.9):\n",
    "    cnn_model = tf.keras.models.Sequential()\n",
    "    cnn_model.add(tf.keras.layers.Conv1D(filters=8, kernel_size=5, padding='same', activation='relu',\n",
    "                                         input_shape=(input_shape, 1)))\n",
    "    cnn_model.add(tf.keras.layers.MaxPool1D(pool_size=2, strides=2, padding='same'))\n",
    "    cnn_model.add(tf.keras.layers.Conv1D(filters=16, kernel_size=5, padding='same', activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.Flatten())\n",
    "    cnn_model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "    cnn_model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    loss = tf.keras.losses.binary_crossentropy\n",
    "    cnn_model.compile(optimizer, loss=loss, metrics=['accuracy'])\n",
    "    return cnn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_csv(file_path, weights_file_path, ppg_column_name):\n",
    "    \"\"\"\n",
    "    Hàm này tải, xử lý, và dự đoán BPM từ một file CSV.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Tải và chuẩn bị dữ liệu (Load and Prep Data) ---\n",
    "    print(f\"Đang đọc file: {file_path}...\")\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        signal = df[ppg_column_name].values.astype('float32')\n",
    "        original_fs = 125\n",
    "    except FileNotFoundError:\n",
    "        print(f\"LỖI: Không tìm thấy file tại '{file_path}'\")\n",
    "        return None, None\n",
    "    except KeyError:\n",
    "        print(f\"LỖI: Không tìm thấy cột '{ppg_column_name}' trong file CSV.\")\n",
    "        print(f\"Các cột có sẵn là: {df.columns.tolist()}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi khi đọc CSV: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # --- 2. Tiền xử lý (Preprocess) ---\n",
    "    print(f\"Tần số gốc: {original_fs}Hz. Tần số mục tiêu: {FREQUENCY_SAMPLING}Hz.\")\n",
    "    if original_fs != FREQUENCY_SAMPLING:\n",
    "        # Resample tín hiệu về 125Hz\n",
    "        new_length = int(len(signal) * FREQUENCY_SAMPLING / original_fs)\n",
    "        signal = resample(signal, new_length)\n",
    "        print(f\"Đã resample tín hiệu. Độ dài mới: {new_length} mẫu.\")\n",
    "    else:\n",
    "        print(\"Tần số gốc đã khớp, không cần resample.\")\n",
    "\n",
    "    # Áp dụng 2 hàm tiền xử lý giống hệt lúc train\n",
    "    signal_processed = baseline_wander_remove(signal, FREQUENCY_SAMPLING)\n",
    "    signal_processed = normalize(signal_processed, FREQUENCY_SAMPLING)\n",
    "    print(\"Đã áp dụng baseline_wander_remove và normalize.\")\n",
    "\n",
    "    # --- 3. Tạo cửa sổ (Create Windows) ---\n",
    "    data_sample = []\n",
    "    window_size = NEIGHBOUR_POINT # NEIGHBOUR_POINT = 50\n",
    "    \n",
    "    # Lặp để tạo các cửa sổ chồng lấn\n",
    "    for i in range(len(signal_processed) - (window_size - 1)):\n",
    "        data_sample.append(signal_processed[i : i + window_size])\n",
    "    \n",
    "    if not data_sample:\n",
    "        print(f\"Tín hiệu quá ngắn (dài {len(signal_processed)} mẫu) để tạo cửa sổ (kích thước {window_size}).\")\n",
    "        return None, None\n",
    "        \n",
    "    # Chuyển sang định dạng model mong muốn (N, 50, 1)\n",
    "    data_sample_np = np.expand_dims(np.array(data_sample, dtype='float32'), axis=2)\n",
    "    print(f\"Đã tạo {data_sample_np.shape[0]} cửa sổ dữ liệu.\")\n",
    "\n",
    "    # --- 4. Tải Model và Trọng số (Load Model) ---\n",
    "    try:\n",
    "        # Gọi hàm từ cell [11b93ad1]\n",
    "        model = tf.keras.models.load_model(\"last_ckt.weights.h5\")\n",
    "        print(f\"Đã tải trọng số từ {weights_file_path}\")\n",
    "    except NameError:\n",
    "        print(\"LỖI: Hàm `get_ppg_model()` chưa được định nghĩa.\")\n",
    "        print(\"Hãy chạy cell [11b93ad1] trước.\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"LỖI khi tải trọng số: {e}\")\n",
    "        print(\"Hãy kiểm tra lại đường dẫn `weights_file_path`.\")\n",
    "        return None, None\n",
    "\n",
    "    # --- 5. Dự đoán (Predict) ---\n",
    "    print(\"Đang chạy dự đoán (model.predict)...\")\n",
    "    prediction_probs = model.predict(data_sample_np, batch_size=128, verbose=0)\n",
    "    print(\"Đã chạy dự đoán xong.\")\n",
    "\n",
    "    # --- 6. Hậu xử lý (Post-process) ---\n",
    "    # Lấy xác suất là đỉnh (cột 1)\n",
    "    prediction_rounded = np.rint(prediction_probs)\n",
    "    predicted_class_1 = prediction_rounded[:, 1]\n",
    "    \n",
    "    # Nhóm các đỉnh lại và bù offset\n",
    "    predicted_peaks = clustering(predicted_class_1) + int(0.1 * FREQUENCY_SAMPLING)\n",
    "    print(f\"Phát hiện được {len(predicted_peaks)} đỉnh.\")\n",
    "\n",
    "    # --- 7. Tính BPM (Calculate BPM) ---\n",
    "    bpm_pred = calculate_average_bpm(predicted_peaks, FREQUENCY_SAMPLING) #\n",
    "    \n",
    "    return predicted_peaks, bpm_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12b6dd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BẮT ĐẦU DỰ ĐOÁN ---\n",
      "Đang đọc file: ppg_test_7500_noisy.csv...\n",
      "Tần số gốc: 125Hz. Tần số mục tiêu: 125Hz.\n",
      "Tần số gốc đã khớp, không cần resample.\n",
      "Đã áp dụng baseline_wander_remove và normalize.\n",
      "Đã tạo 7451 cửa sổ dữ liệu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tải trọng số từ D:\\altium and source projects\\Health monitoring\\AI_trainning\\qrs_detection_dataset\\checkpoint\\mitdb\\run-0\\09.weights.h5\n",
      "Đang chạy dự đoán (model.predict)...\n",
      "Đã chạy dự đoán xong.\n",
      "Phát hiện được 76 đỉnh.\n",
      "\n",
      "--- ✅ KẾT QUẢ CUỐI CÙNG ---\n",
      "Đã tìm thấy các đỉnh tại mẫu (sau resample): [  25  117  230  330  435  534  647  750  846  960 1063 1271 1365 1386\n",
      " 1466 1577 1678 1707 1789 1905 1999 2095 2209 2309 2408 2511 2622 2728\n",
      " 2841 2932 3040 3163 3247 3350 3455 3558 3668 3771 3869 3977 4077 4184\n",
      " 4289 4397 4499 4598 4701 4721 4814 4913 5010 5117 5216 5240 5324 5426\n",
      " 5451 5537 5646 5752 5967 6062 6167 6276 6363 6389 6468 6575 6685 6784\n",
      " 6894 6998 7100 7209 7311 7411]\n",
      "BPM dự đoán trung bình: 74.30 BPM\n"
     ]
    }
   ],
   "source": [
    "my_weights_path = r'D:\\altium and source projects\\Health monitoring\\AI_trainning\\qrs_detection_dataset\\checkpoint\\mitdb\\run-0\\09.weights.h5'\n",
    "my_csv_path = 'ppg_test_7500_noisy.csv'\n",
    "my_ppg_column = 'IR'  # Dựa trên file 1.csv, chọn 'Red (a.u)' hoặc 'Infra Red (a.u)'\n",
    "# 2. GỌI HÀM ĐỂ CHẠY\n",
    "print(\"--- BẮT ĐẦU DỰ ĐOÁN ---\")\n",
    "peaks, bpm = predict_on_csv(my_csv_path, \n",
    "                           my_weights_path, \n",
    "                           my_ppg_column, \n",
    "                           )\n",
    "\n",
    "if peaks is not None:\n",
    "    print(\"\\n--- ✅ KẾT QUẢ CUỐI CÙNG ---\")\n",
    "    print(f\"Đã tìm thấy các đỉnh tại mẫu (sau resample): {peaks}\")\n",
    "    print(f\"BPM dự đoán trung bình: {bpm:.2f} BPM\")\n",
    "else:\n",
    "    print(\"\\n--- ❌ ĐÃ XẢY RA LỖI ---\")\n",
    "    print(\"Quá trình dự đoán thất bại. Vui lòng xem lại thông báo lỗi ở trên.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c81fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# load model keras\n",
    "model = tf.keras.models.load_model(\"last_ckt.weights.h5\")\n",
    "\n",
    "# convert sang tflite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# bật quantization (int8) để chạy được trên MCU\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d463dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã tạo model_data.cc và model_data.h, dung lượng model = 21880 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Tên file input/output\n",
    "input_file = \"model.tflite\"\n",
    "cc_file = \"model_data.cc\"\n",
    "h_file = \"model_data.h\"\n",
    "array_name = \"model_tflite\"\n",
    "\n",
    "# Đọc file .tflite\n",
    "with open(input_file, \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Sinh file .cc\n",
    "with open(cc_file, \"w\") as f:\n",
    "    f.write(f'#include \"{h_file}\"\\n\\n')\n",
    "    f.write(f\"const unsigned char {array_name}[] = {{\\n\")\n",
    "    for i in range(0, len(data), 12):\n",
    "        chunk = data[i:i+12]\n",
    "        f.write(\"  \" + \", \".join(f\"0x{b:02x}\" for b in chunk) + \",\\n\")\n",
    "    f.write(\"};\\n\\n\")\n",
    "    f.write(f\"const unsigned int {array_name}_len = {len(data)};\\n\")\n",
    "\n",
    "# Sinh file .h\n",
    "with open(h_file, \"w\") as f:\n",
    "    f.write(\"#pragma once\\n\\n\")\n",
    "    f.write(\"#include <cstdint>\\n\\n\")\n",
    "    f.write(f\"extern const unsigned char {array_name}[];\\n\")\n",
    "    f.write(f\"extern const unsigned int {array_name}_len;\\n\")\n",
    "\n",
    "print(f\"✅ Đã tạo {cc_file} và {h_file}, dung lượng model = {len(data)} bytes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
